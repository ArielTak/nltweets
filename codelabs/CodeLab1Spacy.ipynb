{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CodeLab 1: Cleaning text data with Spacy - nltweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 4296-BF44\n",
      "\n",
      " Directory of C:\\Users\\riley\\Documents\\Coding\\nltweets\\nltweets-master\\codelabs\n",
      "\n",
      "19/02/23  22:00    <DIR>          .\n",
      "19/02/23  22:00    <DIR>          ..\n",
      "19/02/23  15:06    <DIR>          .ipynb_checkpoints\n",
      "19/02/23  14:59            23,768 CodeLab0TwitterAPI.ipynb\n",
      "19/02/23  22:00            23,716 CodeLab1Spacy.ipynb\n",
      "19/02/20  19:27           324,254 corpus.txt\n",
      "19/02/23  14:04               491 tweets_with_mention_uxdesign.txt\n",
      "19/02/23  10:49               243 twitter_credentials.json\n",
      "               5 File(s)        372,472 bytes\n",
      "               3 Dir(s)  91,350,781,952 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we want to analyze text data, we want to clean the data to remove noise. \n",
    "\n",
    "Lets look at a text file containing a tweet on each line. This raw data is pretty messy, as you can see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"I'm at SF MUNI - L Taraval - @sfmta_muni in San Francisco, CA https://t.co/3N1JXENWs4\"\n",
      "\n",
      "b'@James_Gross @sfmta_muni'\n",
      "\n",
      "b'@sfmta_muni I like the Rate My Ride feature in the Muni Mobile app, but can you add an option to give other types of feedback?  For example, arrival predictions on the 24 line are several minutes out of whack tonight.  Or wondering if the new Metro cars will always be so jerky?'\n",
      "\n",
      "b'People that live and work in San Francisco should be proud of @sfmta_muni supporting @AirResources proposed standard for zero-emission buses https://t.co/TInaTn1zoc https://t.co/Nxukzkco6H'\n",
      "\n",
      "b'People that live and work in San Francisco should be proud of @sfmta_muni supporting @AirResources proposed standard for zero-emission buses https://t.co/TInaTn1zoc https://t.co/Nxukzkco6H'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('corpus.txt') as f:\n",
    "    for line in f.readlines()[:5]:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's load this data into memory... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "with open('corpus.txt') as f:\n",
    "    for line in f.readlines():\n",
    "        lines.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and get rid of the b' ' around these strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, line in enumerate(lines):\n",
    "    lines[index] = line[2:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now what we have is much nicer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm at SF MUNI - L Taraval - @sfmta_muni in San Francisco, CA https://t.co/3N1JXENWs4\n",
      "@James_Gross @sfmta_muni\n",
      "@sfmta_muni I like the Rate My Ride feature in the Muni Mobile app, but can you add an option to give other types of feedback?  For example, arrival predictions on the 24 line are several minutes out of whack tonight.  Or wondering if the new Metro cars will always be so jerky?\n",
      "People that live and work in San Francisco should be proud of @sfmta_muni supporting @AirResources proposed standard for zero-emission buses https://t.co/TInaTn1zoc https://t.co/Nxukzkco6H\n",
      "People that live and work in San Francisco should be proud of @sfmta_muni supporting @AirResources proposed standard for zero-emission buses https://t.co/TInaTn1zoc https://t.co/Nxukzkco6H\n"
     ]
    }
   ],
   "source": [
    "for line in lines[:5]:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets do a couple more things to our text using Spacy, a powerful natural language processing library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to download the 'en' package for Spacy like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\riley\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (2.0.18)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\riley\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from spacy) (1.15.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\riley\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\riley\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from spacy) (2.0.2)\n",
      "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in c:\\users\\riley\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from spacy) (2.0.1)\n",
      "Requirement already satisfied: thinc<6.13.0,>=6.12.1 in c:\\users\\riley\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from spacy) (6.12.1)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in c:\\users\\riley\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from spacy) (0.9.6)\n",
      "Requirement already satisfied: ujson>=1.35 in c:\\users\\riley\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from spacy) (1.35)\n",
      "Requirement already satisfied: dill<0.3,>=0.2 in c:\\users\\riley\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from spacy) (0.2.9)\n",
      "Requirement already satisfied: regex==2018.01.10 in c:\\users\\riley\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from spacy) (2018.1.10)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\riley\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from spacy) (2.21.0)\n",
      "Requirement already satisfied: msgpack<0.6.0,>=0.5.6 in c:\\users\\riley\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.5.6)\n",
      "Requirement already satisfied: msgpack-numpy<0.4.4 in c:\\users\\riley\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.4.3.2)\n",
      "Requirement already satisfied: cytoolz<0.10,>=0.9.0 in c:\\users\\riley\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.9.0.1)\n",
      "Requirement already satisfied: wrapt<1.11.0,>=1.10.0 in c:\\users\\riley\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from thinc<6.13.0,>=6.12.1->spacy) (1.10.11)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in c:\\users\\riley\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from thinc<6.13.0,>=6.12.1->spacy) (4.31.1)\n",
      "Requirement already satisfied: six<2.0.0,>=1.10.0 in c:\\users\\riley\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from thinc<6.13.0,>=6.12.1->spacy) (1.12.0)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in c:\\users\\riley\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\riley\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2018.11.29)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\riley\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\riley\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
      "Requirement already satisfied: toolz>=0.8.0 in c:\\users\\riley\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from cytoolz<0.10,>=0.9.0->thinc<6.13.0,>=6.12.1->spacy) (0.9.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's import Spacy and load 'en'. Below, we store the default Spacy model into the variable 'nlp'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz (37.4MB)\n",
      "Installing collected packages: en-core-web-sm\n",
      "  Running setup.py install for en-core-web-sm: started\n",
      "    Running setup.py install for en-core-web-sm: finished with status 'done'\n",
      "Successfully installed en-core-web-sm-2.0.0\n",
      "\n",
      "    Linking successful\n",
      "    C:\\Users\\riley\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\en_core_web_sm\n",
      "    -->\n",
      "    C:\\Users\\riley\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\spacy\\data\\en\n",
      "\n",
      "    You can now load the model via spacy.load('en')\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You do not have sufficient privilege to perform this operation.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spacy gives us a bunch of features for free. As you can see below, the default Spacy pipeline will run a part-of-speech tagger, dependency parser, and named entity recognizer on our text. We don't need every feature in the pipeline, let's use some basic features for the purposes of this CodeLab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.Tagger at 0xf569f30>),\n",
       " ('parser', <spacy.pipeline.DependencyParser at 0xf547d50>),\n",
       " ('ner', <spacy.pipeline.EntityRecognizer at 0xf547ae0>)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select a sample tweet and run a few preprocessing steps to make it more ready for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@sfmta_muni I like the Rate My Ride feature in the Muni Mobile app, but can you add an option to give other types of feedback?  For example, arrival predictions on the 24 line are several minutes out of whack tonight.  Or wondering if the new Metro cars will always be so jerky?'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can call make_doc(string) on our document to get a Spacy Doc object that adds a bunch of nice metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp.make_doc(lines[2])\n",
    "type(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we can easily tokenize our document, which is splitting it into individual \"tokens.\" Spacy tokens are words tagged with useful properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[@sfmta_muni, I, like, the, Rate, My, Ride, feature, in, the, Muni, Mobile, app, ,, but, can, you, add, an, option, to, give, other, types, of, feedback, ?,  , For, example, ,, arrival, predictions, on, the, 24, line, are, several, minutes, out, of, whack, tonight, .,  , Or, wondering, if, the, new, Metro, cars, will, always, be, so, jerky, ?]\n"
     ]
    }
   ],
   "source": [
    "tokens = [token for token in doc]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, let's use the token's \"is_punct\" attribute to remove punctuation tokens from our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[@sfmta_muni, I, like, the, Rate, My, Ride, feature, in, the, Muni, Mobile, app, but, can, you, add, an, option, to, give, other, types, of, feedback,  , For, example, arrival, predictions, on, the, 24, line, are, several, minutes, out, of, whack, tonight,  , Or, wondering, if, the, new, Metro, cars, will, always, be, so, jerky]\n"
     ]
    }
   ],
   "source": [
    "tokens = [token for token in tokens if not token.is_punct]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's explicitly remove blank tokens from our string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[@sfmta_muni, I, like, the, Rate, My, Ride, feature, in, the, Muni, Mobile, app, but, can, you, add, an, option, to, give, other, types, of, feedback, For, example, arrival, predictions, on, the, 24, line, are, several, minutes, out, of, whack, tonight, Or, wondering, if, the, new, Metro, cars, will, always, be, so, jerky]\n"
     ]
    }
   ],
   "source": [
    "tokens = [token for token in tokens if token.text != ' ']\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's delete non-dictionary words from our text, such as hashtags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I, like, the, Rate, My, feature, in, the, Muni, Mobile, app, but, can, you, add, an, option, to, give, other, types, of, feedback, For, example, arrival, predictions, on, the, 24, line, are, several, minutes, out, of, whack, tonight, Or, wondering, if, the, new, Metro, cars, will, always, be, so, jerky]\n"
     ]
    }
   ],
   "source": [
    "tokens = [token for token in tokens if token.text in nlp.vocab]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also delete stop words using the \"is_stop\" attribute of our tokens. Stop words are common but not meaningful words such as \"the\" and \"in\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I, like, Rate, My, feature, Muni, Mobile, app, add, option, types, feedback, For, example, arrival, predictions, 24, line, minutes, whack, tonight, Or, wondering, new, Metro, cars, jerky]\n"
     ]
    }
   ],
   "source": [
    "tokens = [token for token in tokens if not token.is_stop]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's retrieve the raw text data from our tokens and join them back into a single string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [token.text for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like Rate My feature Muni Mobile app add option types feedback For example arrival predictions 24 line minutes whack tonight Or wondering new Metro cars jerky\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to our original document, our cleaned document is much more concise but retains all the semantically meaningful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "@sfmta_muni I like the Rate My Ride feature in the Muni Mobile app, but can you add an option to give other types of feedback?  For example, arrival predictions on the 24 line are several minutes out of whack tonight.  Or wondering if the new Metro cars will always be so jerky?"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(lines[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more thing: since named entity recognition is particularly interesting to our project, let's use the Spacy pipeline to do some analysis on named entities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, let's pick out a tweet with some clear named entities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reminder: Bus shuttles providing #TThird svc btwn Embarcadero and Bayshore/Sunnydale all day today. Watch for signs showing where to board bus &amp; allow for extra travel time. T and #KIngleside prediction times will not be available. https://t.co/HTJkPtzHAA\n"
     ]
    }
   ],
   "source": [
    "line = lines[82]\n",
    "print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spacy can grab the named entities from this document like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONEY TThird\n",
      "FAC Embarcadero\n",
      "ORG Bayshore/Sunnydale\n",
      "DATE all day today\n",
      "MONEY #KIngleside\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(line)\n",
    "for ent in doc.ents:\n",
    "    print(ent.label_, ent.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spacy correctly picks out the named entities, although makes some mistakes categorizing the entities. For example, Bayshore/Sunnydale is categorized as an organization, but for our purposes, it's a SF MUNI stop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a simple analysis: we can go through our corpus and count up the most frequently appearing named entities. This can help us get an idea of what SF MUNI users care about the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('@SFBART', 104),\n",
       " ('Thanksgiving', 100),\n",
       " ('San Francisco', 64),\n",
       " ('SF', 55),\n",
       " ('Muni', 53),\n",
       " ('@sfmta_muni', 43),\n",
       " ('Embarcadero', 40),\n",
       " ('#', 38),\n",
       " ('2', 38),\n",
       " ('today', 35)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "entities = []\n",
    "for line in lines:\n",
    "    doc = nlp(line)\n",
    "    for ent in doc.ents:\n",
    "        entities.append(str(ent))\n",
    "Counter(entities).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hope this was helpful in learning some of the basic features of Spacy! Questions? DM me @daniel.zou on the sfbrigade Slack"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
